<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>异步 - Tag - 我的全新 Hugo 网站</title>
        <link>http://example.org/tags/%E5%BC%82%E6%AD%A5/</link>
        <description>异步 - Tag - 我的全新 Hugo 网站</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Sat, 27 Nov 2021 16:58:17 &#43;0000</lastBuildDate><atom:link href="http://example.org/tags/%E5%BC%82%E6%AD%A5/" rel="self" type="application/rss+xml" /><item>
    <title>aiohttp使用回调函数边请求边处理</title>
    <link>http://example.org/aiohttp%E4%BD%BF%E7%94%A8%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E8%BE%B9%E8%AF%B7%E6%B1%82%E8%BE%B9%E5%A4%84%E7%90%86/</link>
    <pubDate>Sat, 27 Nov 2021 16:58:17 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/aiohttp%E4%BD%BF%E7%94%A8%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E8%BE%B9%E8%AF%B7%E6%B1%82%E8%BE%B9%E5%A4%84%E7%90%86/</guid>
    <description><![CDATA[我们平时使用Requests的时候，一般是这样写代码的：
1 2 3 4 5 6 7 import requests def parse(html): print(&#39;对 html 进行处理&#39;) html = requests.get(&#39;url&#39;) parse(html) 这是一种非常常见的直线性思维，我先请求网站拿到 html，然后我再把 html 传给负责处理的函数。在整个过程中，“我“担任着调度的角色。
在这种思维方式的影响下，有些同学即使在使用aiohttp写异步爬虫，也是这样写的：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import aiohttp import asyncio async def request(url): async with aiohttp.ClientSession() as session: resp = await session.get(url) html = await resp.text(encoding=&#39;utf-8&#39;) def parse(html): print(&#39;处理 html&#39;) async def main(): url_list = [url1, url2, url3, url4] tasks = [] for url in url_list: tasks.]]></description>
</item>
<item>
    <title>aiohttp学习笔记</title>
    <link>http://example.org/aiohttp%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
    <pubDate>Sat, 27 Nov 2021 09:37:35 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/aiohttp%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
    <description><![CDATA[aiohttp中文文档 https://www.cntofu.com/book/127/aiohttp文档/ClientUsage.md]]></description>
</item>
<item>
    <title>轻松理解 Python中 的 async-await 概念</title>
    <link>http://example.org/%E8%BD%BB%E6%9D%BE%E7%90%86%E8%A7%A3-python%E4%B8%AD-%E7%9A%84-async-await-%E6%A6%82%E5%BF%B5/</link>
    <pubDate>Sat, 27 Nov 2021 07:21:36 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/%E8%BD%BB%E6%9D%BE%E7%90%86%E8%A7%A3-python%E4%B8%AD-%E7%9A%84-async-await-%E6%A6%82%E5%BF%B5/</guid>
    <description><![CDATA[前言 写这篇文章是受 xinghun85 的这篇博客 的启发, 但是人家后面写的东西跳跃太快, 有点没看懂, 自己在此做一个补充.
我希望能用一个最平易近人的例子, 把 Python 协程中的 async/await 概念讲清楚, 希望能够帮助大家有一个形象化的认识.
注: 所有的讲解都在代码的注释里. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 from time import sleep, time def demo1(): &#34;&#34;&#34; 假设我们有三台洗衣机, 现在有三批衣服需要分别放到这三台洗衣机里面洗.]]></description>
</item>
<item>
    <title>python3异步编程async/await原理解释的比较详细的文章</title>
    <link>http://example.org/await%E5%8E%9F%E7%90%86%E8%A7%A3%E9%87%8A%E7%9A%84%E6%AF%94%E8%BE%83%E8%AF%A6%E7%BB%86%E7%9A%84%E6%96%87%E7%AB%A0/</link>
    <pubDate>Sat, 27 Nov 2021 07:06:09 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/await%E5%8E%9F%E7%90%86%E8%A7%A3%E9%87%8A%E7%9A%84%E6%AF%94%E8%BE%83%E8%AF%A6%E7%BB%86%E7%9A%84%E6%96%87%E7%AB%A0/</guid>
    <description><![CDATA[身为Python核心开发组的成员，我对于这门语言的各种细节充满好奇。尽管我很清楚自己不可能对这门语言做到全知全能，但哪怕是为了能够解决各种issue和参与常规的语言设计工作，我也觉得有必要试着接触和理解Python的内核，弄清楚在底层它是怎么工作的。
话虽如此，直到最近我才理解了Python3.5中async/await的工作机制。在此之前，对于async/await语法，我只知道Python3.3中的yield from和Python3.4中的asyncio让这个新语法得以在Python3.5中实现。由于日常工作中没有接触多少网络编程&ndash;asyncio的主要应用领域，虽然它可以做的远不止于此&ndash;我对async/await并没有关注太多。以代码来说，我知道：
1 yield from iterator (大体)等价于:
1 2 from x in iterator: yield x 而且我知道asyncio是个事件循环的框架，支持异步编程，还有这些术语所表示的(基本)意义。但未曾真正的深入研究async/await语法，分析从最基础的指令到实现代码语法功能的过程，我觉得并没有理解Python中的异步编程，这一点甚至让我心烦意乱。因此我决定花点时间弄明白这个语法的工作机制。鉴于我听到许多人说他们也不理解异步编程的工作机制，我写出了这篇论文(是的，这篇博文耗费时间之长，字数之多，让我妻子把它叫做论文)。
由于我希望对这个语法的工作机制有一个完整的理解，这篇论文中会出现涉及CPython的底层技术细节。如果你不关心这些细节，或者无法通过这篇文章完全理解这些细节&ndash;限于篇幅，我不可能详细解释CPython的每个细节，否则这篇文章就要变成一本书了(例如，如果你不知道代码对象具有标识位，那就别在意代码对象是什么，这不是这篇文章的重点)&ndash;那也没什么关系。在每个章节的最后，我都添加了一个概念明确的小结，因此如果你对某个章节的内容不感兴趣，那么可以跳过前面的长篇大论，直接阅读结论。
Python中协程(coroutine)的历史
根据维基百科，“协程是将多个低优先级的任务转换成统一类型的子任务，以实现在多个节点之间停止或唤醒程序运行的程序模块”。这句专业论述翻译成通俗易懂的话就是，“协程就是可以人为暂停执行的函数”。如果你觉得，“这听起来像是生成器(generators)”，那么你是对的。
生成器的概念在Python2.2时的PEP 255中(由于实现了遍历器的协议，生成器也被成为生成器遍历器)第一次被引入。主要受到了Icon语言的影响，生成器允许用户创建一个特殊的遍历器，在生成下一个值时，不会占用额外的内存，并且实现方式非常简单(当然，在自定义类中实现__iter__()和__next__()方法也可以达到不存储遍历器中所有值的效果，但也带来了额外的工作量)。举例来说，如果你想实现自己的range()函数，最直接的方式是创建一个整数数组：
1 2 3 4 5 6 7 8 def eager_range(up_to): &#34;&#34;&#34;创建一个从0到变量up_to的数组，不包括up_to&#34;&#34;&#34; sequence = [] index = [] while index &lt; up_to: sequence.append(index) index += 1 return sequence 简单直白，但这个函数的问题是，如果你需要的序列很大，比如0到一百万，你必须创建一个包含了所有整数的长度是一百万的数组。如果使用生成器，你就可以毫不费力的创建一个从0到上限前一个整数的生成器。所占用的内存也只是每次生成的一个整数。
1 2 3 4 5 6 def lazy_range(up_to): &#34;&#34;&#34;一个从0到变量up_to，不包括up_to的生成器&#34;&#34;&#34; index = 0 while index &lt; up_to: yield index index += 1 函数可以在遇到yield表达式时暂停执行&ndash;尽管yield直到Python2.]]></description>
</item>
<item>
    <title>requests、aiohttp、httpx对比</title>
    <link>http://example.org/requestsaiohttphttpx%E5%AF%B9%E6%AF%94/</link>
    <pubDate>Mon, 01 Jan 0001 00:00:00 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/requestsaiohttphttpx%E5%AF%B9%E6%AF%94/</guid>
    <description><![CDATA[来源：https://learnku.com/articles/54989 在 Python 众多的 HTTP 客户端中，最有名的莫过于 requests、aiohttp 和 httpx。在不借助其他第三方库的情况下，requests 只能发送同步请求；aiohttp 只能发送异步请求；httpx 既能发送同步请求，又能发送异步请求。
所谓的同步请求，是指在单进程单线程的代码中，发起一次请求后，在收到返回结果之前，不能发起下一次请求。所谓异步请求，是指在单进程单线程的代码中，发起一次请求后，在等待网站返回结果的时间里，可以继续发送更多请求。
今天我们来一个浅度测评，仅仅以多次发送 GET 请求这个角度来对比这三个库的性能。
当然测试结果与网速有关，不过在同一段时间的同一个网络测试出来，还是能看得出来问题的。
requests 发送请求 1 2 3 4 5 6 7 8 9 10 11 12 import requests url = &#39;https://www.baidu.com/&#39; headers = headers = { &#39;User-Agent&#39;: &#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36&#39;} def main(): res = requests.get(url,headers=headers) print(res.status_code) if __name__ == &#39;__main__&#39;: main() 使用 requests.post 每次都会创建新的连接，速度较慢。而如果首先初始化一个 Session，那么 requests 会保持连接，从而大大提高请求速度。所以在这次测评中，我们分别对两种情况进行测试]]></description>
</item>
<item>
    <title>异步并发aiohttp</title>
    <link>http://example.org/%E5%BC%82%E6%AD%A5%E5%B9%B6%E5%8F%91aiohttp/</link>
    <pubDate>Mon, 01 Jan 0001 00:00:00 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/%E5%BC%82%E6%AD%A5%E5%B9%B6%E5%8F%91aiohttp/</guid>
    <description><![CDATA[1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 import time from aiohttp import ClientSession,TCPConnector from pprint import pprint as print import asyncio url = &#39;https://api.panhvhg.xyz/api/v3/channels/968/connect&#39; url=&#39;https://api.panhvhg.xyz/api/v3/channels/0/connect&#39; headers = { &#39;Host&#39;: &#39;api.panhvhg.xyz&#39;, &#39;api-version&#39;: &#39;v3.]]></description>
</item>
</channel>
</rss>

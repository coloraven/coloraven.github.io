<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Python - Category - 我的全新 Hugo 网站</title>
        <link>http://example.org/categories/python/</link>
        <description>Python - Category - 我的全新 Hugo 网站</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Tue, 18 Apr 2023 14:18:50 &#43;0000</lastBuildDate><atom:link href="http://example.org/categories/python/" rel="self" type="application/rss+xml" /><item>
    <title>Pandas 一列分多列，一行分多行，提取列中的要素，实现vlookup功能等</title>
    <link>http://example.org/pandas%E4%B8%80%E5%88%97%E5%88%86%E5%A4%9A%E5%88%97%E4%B8%80%E8%A1%8C%E5%88%86%E5%A4%9A%E8%A1%8C%E7%9A%84%E5%AE%9E%E7%8E%B0/</link>
    <pubDate>Tue, 18 Apr 2023 14:18:50 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/pandas%E4%B8%80%E5%88%97%E5%88%86%E5%A4%9A%E5%88%97%E4%B8%80%E8%A1%8C%E5%88%86%E5%A4%9A%E8%A1%8C%E7%9A%84%E5%AE%9E%E7%8E%B0/</guid>
    <description><![CDATA[转载自https://blog.csdn.net/Asher117/article/details/84346073
摘要 在进行数据分析时，我们经常需要把DataFrame的一列拆成多列或者根据某列把一行拆成多行，这篇文章主要讲解这两个目标的实现。 读取数据 一列分多列 将City列转成多列（以|为分隔符）,这里使用匿名函数lambda来将City列拆成两列。 一行分多行 将DataFrame一行拆成多行（以|为分隔符）
方法一 在刚刚得到的DataFrame基础上操作,如下图所以，可以明显看到我们按照City列将DataFrame拆成了多行。主要是先将DataFrame拆成多列，然后拆成多个DataFrame再使用concat组合。但是这种方法碰到City列切割不均匀的时候可能会麻烦一点，因此，这个时候你可以使用万能方法二。 方法二 这个方法的主要思想是，首先将DataFrame中需要拆分的列进行拆分，再使用stack（）进行轴变换，然后通过index来join即可，如下所示。 首先，将刚刚的df还原成原始形式： 接下来取出其City列，并切分成多列之后轴转换，之后重新设置索引，并且重命名为Company 最后删除df里面的Country列，并将DataFrame-df1 使用join到df里面得到最后的结果。 正则提取某列的要素并按要素分列 有个csv表格（以逗号,作为分隔符），数据样本如下，其中电话号码列中电话号码的个数不确定：
姓名 性别 电话号码 张三 男 电话号码:13788881111;+86-18911112222;其码:86-17722221111;其号码:+86 13565459999;86 15366558877 王五 女 16535468764;+77-16888779512;+86 13565457898;其他+87-13544569871 使用pandas库结合正则表达式将第三列中的手机号码提取后每个号码单独成列，与原来的数据一起形成新的行。 预期结果：
姓名 性别 电话号码 (0, 0) (0, 1) (0, 2) (0, 3) (0, 4) 张三 男 电话号码:13788881111;+86-18911112222;其码:86-17722221111;其号码:+86 13565459999;86 15366558877 13788881111 18911112222 17722221111 13565459999 15366558877 王五 女 16535468764;+77-16888779512;+86 13565457898;其他+87-13544569871 16535468764 16888779512 13565457898 13544569871 实现代码一 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import pandas as pd df = pd.]]></description>
</item>
<item>
    <title>Python和Golang超大文本文件处理</title>
    <link>http://example.org/python%E5%92%8Cgolang%E8%B6%85%E5%A4%A7%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86/</link>
    <pubDate>Tue, 20 Dec 2022 15:26:31 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/python%E5%92%8Cgolang%E8%B6%85%E5%A4%A7%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86/</guid>
    <description><![CDATA[Python Python中迭代读取超大文本文件，每次读取1000行。 在python中，我们可以使用yield关键字和for循环实现迭代读取超大文本文件，每次读取1000行。
例如，我们可以定义一个函数read_lines_by_1000()，每次yield 1000行的数据：
1 2 3 4 5 6 7 8 9 def read_lines_by_1000(filename): with open(filename, &#39;r&#39;) as f: lines = [] for line in f: lines.append(line) if len(lines) == 1000: yield lines lines = [] yield lines 然后，我们可以使用for循环迭代读取超大文本文件：
1 2 3 4 filename = &#39;data.txt&#39; for lines in read_lines_by_1000(filename): print(lines) # 处理lines中的数据 有比这个效率更高的方法吗 这样就可以在python中迭代读取超大文本文件，每次读取1000行了。 使用yield关键字和for循环迭代读取超大文本文件，每次读取1000行的方法已经是目前效率最高的方法之一。
如果想要提升效率，还可以考虑以下几种方法：
尽量使用内存映射文件读取超大文本文件，这样可以避免将数据从磁盘读取到内存中，从而提升读取速度。
尽量使用多线程读取超大文本文件，从而提升读取速度。
尽量使用多进程读取超大文本文件，从而提升读取速度。
尽量使用单个较大的缓冲区读取超大文本文件，从而提升读取速度。
需要注意的是，使用上述方法时可能会带来一些问题，例如内存占用过大，多线程/多进程同步问题等。因此，需要根据实际情况选择适合的方法。
python如何正确处理超大文本文件，防止内存吃不消。 在python中，可以使用以下几种方法正确处理超大文本文件，防止内存吃不消：
使用yield关键字和for循环迭代读取超大文本文件，每次读取一定数量的行。这样可以避免将整个文件一次性读取到内存中，从而防止内存吃不消。
使用内存映射文件读取超大文本文件。这样可以避免将数据从磁盘读取到内存中，从而防止内存吃不消。
使用多线程/多进程读取超大文本文件。这样可以分担读取超大文本文件的负担，从而防止内存吃不消。
使用单个较大的缓冲区读取超大文本文件。这样可以减少读取超大文本文件时的系统调用次数，从而提升读取速度，防止内存吃不消。]]></description>
</item>
<item>
    <title>Pandas学习笔记</title>
    <link>http://example.org/pandas%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
    <pubDate>Tue, 20 Dec 2022 14:50:22 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/pandas%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
    <description><![CDATA[Pandas 统计出每行非空的列数目 在 pandas 中，可以使用 DataFrame.count() 方法来统计每行非空的列数目。该方法返回一个新的 DataFrame，其中包含每列的非空值的数量。例如：
1 2 3 4 5 6 7 8 9 import pandas as pd # 创建一个示例数据帧 df = pd.DataFrame({&#39;A&#39;: [1, 2, 3, 4], &#39;B&#39;: [5, 6, 7, 8], &#39;C&#39;: [9, 10, None, 12]}) print(df) # 统计每行非空的列数目 non_null_counts = df.count() print(non_null_counts) 1 2 3 4 5 6 7 8 9 10 11 输出结果如下： A B C 0 1 5 9.0 1 2 6 10.0 2 3 7 NaN 3 4 8 12.]]></description>
</item>
<item>
    <title>Pandas条件定位单元格【类似select 字段 from 表 where 其他字段=某值】</title>
    <link>http://example.org/pandas%E6%9D%A1%E4%BB%B6%E5%AE%9A%E4%BD%8D%E5%8D%95%E5%85%83%E6%A0%BC%E7%B1%BB%E4%BC%BCsql%E6%9F%A5%E8%AF%A2/</link>
    <pubDate>Wed, 04 May 2022 21:02:56 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/pandas%E6%9D%A1%E4%BB%B6%E5%AE%9A%E4%BD%8D%E5%8D%95%E5%85%83%E6%A0%BC%E7%B1%BB%E4%BC%BCsql%E6%9F%A5%E8%AF%A2/</guid>
    <description><![CDATA[背景 实践当中，经常需要在Excel表中根据某一列的值去查看另一列对应的值。 比如，根据下表（假设存放在datas.xlsx）中姓名，查找其对应电话号码。 这里顺便记录一下这个网站可以方便的在excel、json、csv、yaml、markdown、xml、html表格之间互转：https://tableconvert.com/excel-to-markdown
序号 姓名 电话号码 年龄 性别 1 张三 4563453 39 男 2 李四 3453453 25 男 3 王五 2323423 18 女 4 李六 2342342 18 男 实操 1 2 3 import pandas as pd df = pd.read_excel(&#39;datas.xlsx&#39;,header=0,encoding=&#39;gbk&#39;) # header默认为0，即从第1行开始读取数据。 gbk为了支持中文 第一步 读取后Pandas默认会根据行数从0开始设置行索引，而不是将第一列作为行索引。 将姓名列设为行索引
1 df = df.set_index(&#39;姓名&#39;) 第二步 使用函数进行定位 at和loc两个函数均可，听说loc更快
1 df.at[&#39;李六&#39;,&#39;电话号码&#39;] 列数据转换 列数据转换，比如，将电话号码列数据转换为字符串类型
1 df[&#39; 电话号码&#39;] = df[&#39; 电话号码&#39;].apply(str) ]]></description>
</item>
<item>
    <title>Python实现对大文件的增量读取</title>
    <link>http://example.org/python%E5%AE%9E%E7%8E%B0%E5%AF%B9%E5%A4%A7%E6%96%87%E4%BB%B6%E7%9A%84%E5%A2%9E%E9%87%8F%E8%AF%BB%E5%8F%96/</link>
    <pubDate>Wed, 01 Dec 2021 13:15:51 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/python%E5%AE%9E%E7%8E%B0%E5%AF%B9%E5%A4%A7%E6%96%87%E4%BB%B6%E7%9A%84%E5%A2%9E%E9%87%8F%E8%AF%BB%E5%8F%96/</guid>
    <description><![CDATA[背景 前段时间在做一个算法测试，需要对源于日志的数据进行分析才能获取到结果；日志文件较大，所以想要获取数据的变化曲线，增量读取是最好的方式。
网上有很多人的技术博客都是写的用for循环readline以及一个计数器去增量读取，假如文件很大，遍历一次太久。而且对于很多大文件的增量读取，如果遍历每一行比对历史记录的输出或者全都加载到内存通过历史记录的索引查找，是非常浪费资源的，
获取文件句柄的基本理论中就包含指针操作。linux的文件描述符的struct里有一个f_pos的这么个属性，里面存着文件当前读取位置，通过这个东东经过vfs的一系列映射就会得到硬盘存储的位置了，所以很直接，很快。
在Python中的读取文件的方法也有类似的属性。
具体实现 Python中相关方法的核心函数如下：
函数 作用 tell() 返回文件当前位置 seek() 从指定位置开始读取信息 其中seek()有三种模式：
f.seek(p,0) 移动当文件第p个字节处，绝对位置 f.seek(p,1) 移动到相对于当前位置之后的p个字节 f.seek(p,2) 移动到相对文章尾之后的p个字节 参考代码：
1 2 3 4 5 6 7 8 9 10 #!/usr/bin/python fd=open(&#34;test.txt&#34;,&#39;r&#39;) #获得一个句柄 for i in xrange(1,3): #读取三行数据 fd.readline() label=fd.tell() #记录读取到的位置 fd.close() #关闭文件 #再次阅读文件 fd=open(&#34;test.txt&#34;,&#39;r&#39;) #获得一个句柄 fd.seek(label,0)# 把文件读取指针移动到之前记录的位置 fd.readline() #接着上次的位置继续向下读取 拓展 如何得知这个大文件行数，以及变化 我的想法：
方式1： 遍历\n字符。
方式2： 开始时就在for循环中对fd.readline()计数，变化的部分（用上文说的seek、tell函数做）再用for循环fd.readline()进行统计。
如何避免文件读取时，内存溢出 可以通过 read 函数的chunk关键字来指定每次读区数据的大小 使用生成器确保只有在数据被调用时才会生成 具体方法封装如下：
1 2 3 4 5 6 7 8 9 def read_in_chunks(file_path, chunk=100 * 100): # 通过chunk指定每次读取文件的大小防止内存占用过大 file_object = open(file_path, &#34;r&#34;) while True: data = file_object.]]></description>
</item>
<item>
    <title>Python计算大文件行数方法及性能比较</title>
    <link>http://example.org/python%E8%AE%A1%E7%AE%97%E5%A4%A7%E6%96%87%E4%BB%B6%E8%A1%8C%E6%95%B0%E6%96%B9%E6%B3%95%E5%8F%8A%E6%80%A7%E8%83%BD%E6%AF%94%E8%BE%83/</link>
    <pubDate>Wed, 01 Dec 2021 13:01:57 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/python%E8%AE%A1%E7%AE%97%E5%A4%A7%E6%96%87%E4%BB%B6%E8%A1%8C%E6%95%B0%E6%96%B9%E6%B3%95%E5%8F%8A%E6%80%A7%E8%83%BD%E6%AF%94%E8%BE%83/</guid>
    <description><![CDATA[如何使用Python快速高效地统计出大文件的总行数, 下面是一些实现方法和性能的比较。
实现方法 readlines方法读所有行 1 2 def readline_count(file_name): return len(open(file_name).readlines()) 依次读取每行 1 2 3 4 5 def simple_count(file_name): lines = 0 for _ in open(file_name): lines += 1 return lines 使用sum函数计数 1 2 def sum_count(file_name): return sum(1 for _ in open(file_name)) enumerate枚举计数 1 2 3 4 5 def enumerate_count(file_name): with open(file_name) as f: for count, _ in enumerate(f, 1): pass return count buff+count每次读取固定大小,然后统计行数 1 2 3 4 5 6 7 8 9 def buff_count(file_name): with open(file_name, &#39;rb&#39;) as f: count = 0 buf_size = 1024 * 1024 buf = f.]]></description>
</item>
<item>
    <title>pip离线安装依赖库</title>
    <link>http://example.org/pip%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E4%BE%9D%E8%B5%96%E5%BA%93/</link>
    <pubDate>Wed, 01 Dec 2021 10:43:09 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/pip%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E4%BE%9D%E8%B5%96%E5%BA%93/</guid>
    <description><![CDATA[记录下命令，下载所需依赖库，在不能联网的机器上离线安装。
1 2 3 4 5 6 7 8 9 10 11 # 查看 pip list # 依赖库信息格式输出 pip freeze &gt; requirements.txt # 仅下载 pip download -r requirements.txt # 安装 pip install --no-index --find-links=dir_path -r requirements.txt ]]></description>
</item>
<item>
    <title>aiohttp使用回调函数边请求边处理</title>
    <link>http://example.org/aiohttp%E4%BD%BF%E7%94%A8%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E8%BE%B9%E8%AF%B7%E6%B1%82%E8%BE%B9%E5%A4%84%E7%90%86/</link>
    <pubDate>Sat, 27 Nov 2021 16:58:17 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/aiohttp%E4%BD%BF%E7%94%A8%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E8%BE%B9%E8%AF%B7%E6%B1%82%E8%BE%B9%E5%A4%84%E7%90%86/</guid>
    <description><![CDATA[我们平时使用Requests的时候，一般是这样写代码的：
1 2 3 4 5 6 7 import requests def parse(html): print(&#39;对 html 进行处理&#39;) html = requests.get(&#39;url&#39;) parse(html) 这是一种非常常见的直线性思维，我先请求网站拿到 html，然后我再把 html 传给负责处理的函数。在整个过程中，“我“担任着调度的角色。
在这种思维方式的影响下，有些同学即使在使用aiohttp写异步爬虫，也是这样写的：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import aiohttp import asyncio async def request(url): async with aiohttp.ClientSession() as session: resp = await session.get(url) html = await resp.text(encoding=&#39;utf-8&#39;) def parse(html): print(&#39;处理 html&#39;) async def main(): url_list = [url1, url2, url3, url4] tasks = [] for url in url_list: tasks.]]></description>
</item>
<item>
    <title>轻松理解 Python中 的 async-await 概念</title>
    <link>http://example.org/%E8%BD%BB%E6%9D%BE%E7%90%86%E8%A7%A3-python%E4%B8%AD-%E7%9A%84-async-await-%E6%A6%82%E5%BF%B5/</link>
    <pubDate>Sat, 27 Nov 2021 07:21:36 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/%E8%BD%BB%E6%9D%BE%E7%90%86%E8%A7%A3-python%E4%B8%AD-%E7%9A%84-async-await-%E6%A6%82%E5%BF%B5/</guid>
    <description><![CDATA[前言 写这篇文章是受 xinghun85 的这篇博客 的启发, 但是人家后面写的东西跳跃太快, 有点没看懂, 自己在此做一个补充.
我希望能用一个最平易近人的例子, 把 Python 协程中的 async/await 概念讲清楚, 希望能够帮助大家有一个形象化的认识.
注: 所有的讲解都在代码的注释里. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 from time import sleep, time def demo1(): &#34;&#34;&#34; 假设我们有三台洗衣机, 现在有三批衣服需要分别放到这三台洗衣机里面洗.]]></description>
</item>
<item>
    <title>python3异步编程async/await原理解释的比较详细的文章</title>
    <link>http://example.org/await%E5%8E%9F%E7%90%86%E8%A7%A3%E9%87%8A%E7%9A%84%E6%AF%94%E8%BE%83%E8%AF%A6%E7%BB%86%E7%9A%84%E6%96%87%E7%AB%A0/</link>
    <pubDate>Sat, 27 Nov 2021 07:06:09 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/await%E5%8E%9F%E7%90%86%E8%A7%A3%E9%87%8A%E7%9A%84%E6%AF%94%E8%BE%83%E8%AF%A6%E7%BB%86%E7%9A%84%E6%96%87%E7%AB%A0/</guid>
    <description><![CDATA[身为Python核心开发组的成员，我对于这门语言的各种细节充满好奇。尽管我很清楚自己不可能对这门语言做到全知全能，但哪怕是为了能够解决各种issue和参与常规的语言设计工作，我也觉得有必要试着接触和理解Python的内核，弄清楚在底层它是怎么工作的。
话虽如此，直到最近我才理解了Python3.5中async/await的工作机制。在此之前，对于async/await语法，我只知道Python3.3中的yield from和Python3.4中的asyncio让这个新语法得以在Python3.5中实现。由于日常工作中没有接触多少网络编程&ndash;asyncio的主要应用领域，虽然它可以做的远不止于此&ndash;我对async/await并没有关注太多。以代码来说，我知道：
1 yield from iterator (大体)等价于:
1 2 from x in iterator: yield x 而且我知道asyncio是个事件循环的框架，支持异步编程，还有这些术语所表示的(基本)意义。但未曾真正的深入研究async/await语法，分析从最基础的指令到实现代码语法功能的过程，我觉得并没有理解Python中的异步编程，这一点甚至让我心烦意乱。因此我决定花点时间弄明白这个语法的工作机制。鉴于我听到许多人说他们也不理解异步编程的工作机制，我写出了这篇论文(是的，这篇博文耗费时间之长，字数之多，让我妻子把它叫做论文)。
由于我希望对这个语法的工作机制有一个完整的理解，这篇论文中会出现涉及CPython的底层技术细节。如果你不关心这些细节，或者无法通过这篇文章完全理解这些细节&ndash;限于篇幅，我不可能详细解释CPython的每个细节，否则这篇文章就要变成一本书了(例如，如果你不知道代码对象具有标识位，那就别在意代码对象是什么，这不是这篇文章的重点)&ndash;那也没什么关系。在每个章节的最后，我都添加了一个概念明确的小结，因此如果你对某个章节的内容不感兴趣，那么可以跳过前面的长篇大论，直接阅读结论。
Python中协程(coroutine)的历史
根据维基百科，“协程是将多个低优先级的任务转换成统一类型的子任务，以实现在多个节点之间停止或唤醒程序运行的程序模块”。这句专业论述翻译成通俗易懂的话就是，“协程就是可以人为暂停执行的函数”。如果你觉得，“这听起来像是生成器(generators)”，那么你是对的。
生成器的概念在Python2.2时的PEP 255中(由于实现了遍历器的协议，生成器也被成为生成器遍历器)第一次被引入。主要受到了Icon语言的影响，生成器允许用户创建一个特殊的遍历器，在生成下一个值时，不会占用额外的内存，并且实现方式非常简单(当然，在自定义类中实现__iter__()和__next__()方法也可以达到不存储遍历器中所有值的效果，但也带来了额外的工作量)。举例来说，如果你想实现自己的range()函数，最直接的方式是创建一个整数数组：
1 2 3 4 5 6 7 8 def eager_range(up_to): &#34;&#34;&#34;创建一个从0到变量up_to的数组，不包括up_to&#34;&#34;&#34; sequence = [] index = [] while index &lt; up_to: sequence.append(index) index += 1 return sequence 简单直白，但这个函数的问题是，如果你需要的序列很大，比如0到一百万，你必须创建一个包含了所有整数的长度是一百万的数组。如果使用生成器，你就可以毫不费力的创建一个从0到上限前一个整数的生成器。所占用的内存也只是每次生成的一个整数。
1 2 3 4 5 6 def lazy_range(up_to): &#34;&#34;&#34;一个从0到变量up_to，不包括up_to的生成器&#34;&#34;&#34; index = 0 while index &lt; up_to: yield index index += 1 函数可以在遇到yield表达式时暂停执行&ndash;尽管yield直到Python2.]]></description>
</item>
</channel>
</rss>

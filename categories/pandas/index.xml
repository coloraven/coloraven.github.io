<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Pandas - Category - 我的全新 Hugo 网站</title>
        <link>http://example.org/categories/pandas/</link>
        <description>Pandas - Category - 我的全新 Hugo 网站</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Tue, 18 Apr 2023 14:18:50 &#43;0000</lastBuildDate><atom:link href="http://example.org/categories/pandas/" rel="self" type="application/rss+xml" /><item>
    <title>Pandas 一列分多列，一行分多行，提取列中的要素，实现vlookup功能等</title>
    <link>http://example.org/pandas%E4%B8%80%E5%88%97%E5%88%86%E5%A4%9A%E5%88%97%E4%B8%80%E8%A1%8C%E5%88%86%E5%A4%9A%E8%A1%8C%E7%9A%84%E5%AE%9E%E7%8E%B0/</link>
    <pubDate>Tue, 18 Apr 2023 14:18:50 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/pandas%E4%B8%80%E5%88%97%E5%88%86%E5%A4%9A%E5%88%97%E4%B8%80%E8%A1%8C%E5%88%86%E5%A4%9A%E8%A1%8C%E7%9A%84%E5%AE%9E%E7%8E%B0/</guid>
    <description><![CDATA[转载自https://blog.csdn.net/Asher117/article/details/84346073
摘要 在进行数据分析时，我们经常需要把DataFrame的一列拆成多列或者根据某列把一行拆成多行，这篇文章主要讲解这两个目标的实现。 读取数据 一列分多列 将City列转成多列（以|为分隔符）,这里使用匿名函数lambda来将City列拆成两列。 一行分多行 将DataFrame一行拆成多行（以|为分隔符）
方法一 在刚刚得到的DataFrame基础上操作,如下图所以，可以明显看到我们按照City列将DataFrame拆成了多行。主要是先将DataFrame拆成多列，然后拆成多个DataFrame再使用concat组合。但是这种方法碰到City列切割不均匀的时候可能会麻烦一点，因此，这个时候你可以使用万能方法二。 方法二 这个方法的主要思想是，首先将DataFrame中需要拆分的列进行拆分，再使用stack（）进行轴变换，然后通过index来join即可，如下所示。 首先，将刚刚的df还原成原始形式： 接下来取出其City列，并切分成多列之后轴转换，之后重新设置索引，并且重命名为Company 最后删除df里面的Country列，并将DataFrame-df1 使用join到df里面得到最后的结果。 正则提取某列的要素并按要素分列 有个csv表格（以逗号,作为分隔符），数据样本如下，其中电话号码列中电话号码的个数不确定：
姓名 性别 电话号码 张三 男 电话号码:13788881111;+86-18911112222;其码:86-17722221111;其号码:+86 13565459999;86 15366558877 王五 女 16535468764;+77-16888779512;+86 13565457898;其他+87-13544569871 使用pandas库结合正则表达式将第三列中的手机号码提取后每个号码单独成列，与原来的数据一起形成新的行。 预期结果：
姓名 性别 电话号码 (0, 0) (0, 1) (0, 2) (0, 3) (0, 4) 张三 男 电话号码:13788881111;+86-18911112222;其码:86-17722221111;其号码:+86 13565459999;86 15366558877 13788881111 18911112222 17722221111 13565459999 15366558877 王五 女 16535468764;+77-16888779512;+86 13565457898;其他+87-13544569871 16535468764 16888779512 13565457898 13544569871 实现代码一 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import pandas as pd df = pd.]]></description>
</item>
<item>
    <title>Python和Golang超大文本文件处理</title>
    <link>http://example.org/python%E5%92%8Cgolang%E8%B6%85%E5%A4%A7%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86/</link>
    <pubDate>Tue, 20 Dec 2022 15:26:31 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/python%E5%92%8Cgolang%E8%B6%85%E5%A4%A7%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86/</guid>
    <description><![CDATA[Python Python中迭代读取超大文本文件，每次读取1000行。 在python中，我们可以使用yield关键字和for循环实现迭代读取超大文本文件，每次读取1000行。
例如，我们可以定义一个函数read_lines_by_1000()，每次yield 1000行的数据：
1 2 3 4 5 6 7 8 9 def read_lines_by_1000(filename): with open(filename, &#39;r&#39;) as f: lines = [] for line in f: lines.append(line) if len(lines) == 1000: yield lines lines = [] yield lines 然后，我们可以使用for循环迭代读取超大文本文件：
1 2 3 4 filename = &#39;data.txt&#39; for lines in read_lines_by_1000(filename): print(lines) # 处理lines中的数据 有比这个效率更高的方法吗 这样就可以在python中迭代读取超大文本文件，每次读取1000行了。 使用yield关键字和for循环迭代读取超大文本文件，每次读取1000行的方法已经是目前效率最高的方法之一。
如果想要提升效率，还可以考虑以下几种方法：
尽量使用内存映射文件读取超大文本文件，这样可以避免将数据从磁盘读取到内存中，从而提升读取速度。
尽量使用多线程读取超大文本文件，从而提升读取速度。
尽量使用多进程读取超大文本文件，从而提升读取速度。
尽量使用单个较大的缓冲区读取超大文本文件，从而提升读取速度。
需要注意的是，使用上述方法时可能会带来一些问题，例如内存占用过大，多线程/多进程同步问题等。因此，需要根据实际情况选择适合的方法。
python如何正确处理超大文本文件，防止内存吃不消。 在python中，可以使用以下几种方法正确处理超大文本文件，防止内存吃不消：
使用yield关键字和for循环迭代读取超大文本文件，每次读取一定数量的行。这样可以避免将整个文件一次性读取到内存中，从而防止内存吃不消。
使用内存映射文件读取超大文本文件。这样可以避免将数据从磁盘读取到内存中，从而防止内存吃不消。
使用多线程/多进程读取超大文本文件。这样可以分担读取超大文本文件的负担，从而防止内存吃不消。
使用单个较大的缓冲区读取超大文本文件。这样可以减少读取超大文本文件时的系统调用次数，从而提升读取速度，防止内存吃不消。]]></description>
</item>
<item>
    <title>Pandas学习笔记</title>
    <link>http://example.org/pandas%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
    <pubDate>Tue, 20 Dec 2022 14:50:22 &#43;0000</pubDate>
    <author>五彩斑斓的黑</author>
    <guid>http://example.org/pandas%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
    <description><![CDATA[Pandas 统计出每行非空的列数目 在 pandas 中，可以使用 DataFrame.count() 方法来统计每行非空的列数目。该方法返回一个新的 DataFrame，其中包含每列的非空值的数量。例如：
1 2 3 4 5 6 7 8 9 import pandas as pd # 创建一个示例数据帧 df = pd.DataFrame({&#39;A&#39;: [1, 2, 3, 4], &#39;B&#39;: [5, 6, 7, 8], &#39;C&#39;: [9, 10, None, 12]}) print(df) # 统计每行非空的列数目 non_null_counts = df.count() print(non_null_counts) 1 2 3 4 5 6 7 8 9 10 11 输出结果如下： A B C 0 1 5 9.0 1 2 6 10.0 2 3 7 NaN 3 4 8 12.]]></description>
</item>
</channel>
</rss>
